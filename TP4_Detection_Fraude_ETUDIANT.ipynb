{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XECnNu7kABOa"
      },
      "source": [
        "# TP4 - DÉTECTION DE FRAUDE BANCAIRE\n",
        "## Optimisation ML & Feature Engineering Avancé\n",
        "\n",
        "**Master 1 Data Engineering - Concepts & Techno IA**\n",
        "**Durée : 7 heures**\n",
        "**Nom & Prénom : PIBRE Alec**\n",
        "\n",
        "---\n",
        "\n",
        "### Objectifs\n",
        "- Maîtriser le Feature Engineering avancé\n",
        "- Gérer des données fortement déséquilibrées (0.17% de fraudes)\n",
        "- Optimiser des hyperparamètres avec GridSearchCV\n",
        "- Construire des Pipelines ML complets\n",
        "- Analyser la performance (ROC, Learning Curves, Feature Importance)\n",
        "\n",
        "### Mission\n",
        "Développer un modèle de détection de fraude avec :\n",
        "- **Recall ≥ 0.85** (détecter 85% des fraudes)\n",
        "- **Precision maximale** (minimiser les faux positifs)\n",
        "- **Explicabilité** (Feature Importance)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsV_VCDqABOb"
      },
      "source": [
        "## IMPORTS & CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x5WgKuLABOb"
      },
      "outputs": [],
      "source": [
        "# Imports standards\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration visualisation\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Reproductibilité\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(\" Imports réussis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0iID8eYABOc"
      },
      "outputs": [],
      "source": [
        "# Imports ML\n",
        "from sklearn.model_selection import (\n",
        " train_test_split, StratifiedKFold, TimeSeriesSplit,\n",
        " GridSearchCV, cross_val_score, learning_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Modèles\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Métriques\n",
        "from sklearn.metrics import (\n",
        " classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        " roc_auc_score, average_precision_score, precision_recall_curve,\n",
        " roc_curve, auc, f1_score, precision_score, recall_score\n",
        ")\n",
        "\n",
        "# Gestion déséquilibre\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "print(\" Imports réussis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMXCjJHhABOc"
      },
      "source": [
        "---\n",
        "## PARTIE 1 : EXPLORATION & FEATURE ENGINEERING (2h)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FKo4L37ABOc"
      },
      "source": [
        "### 1.1 Chargement des Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "6MavuKVaABOc",
        "outputId": "312252f3-b182-420a-9e25-24a26b3aeaf7"
      },
      "outputs": [],
      "source": [
        "# TODO: Charger le dataset creditcard.csv depuis le dossier ../data/\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('../data/creditcard.csv')\n",
        "\n",
        "\n",
        "print(f\"Shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aw3pXMnABOd"
      },
      "outputs": [],
      "source": [
        "# TODO: Afficher les informations du dataset\n",
        "\n",
        "print(\"=== Informations générales ===\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmD02UiuABOd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Dimensions ===\")\n",
        "print(\"Nombre de lignes et colonnes :\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvb2TaNSABOd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Colonnes ===\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdnPsbrYABOd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Aperçu des premières lignes ===\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6ZXHTD3ABOd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Statistiques descriptives ===\")\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdWYkoAUABOd"
      },
      "source": [
        "### 1.2 Analyse du Déséquilibre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVjHmQqPABOd"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculer et afficher :\n",
        "# - Nombre de transactions légitimes (Class = 0)\n",
        "# - Nombre de fraudes (Class = 1)\n",
        "# - Pourcentage de fraudes\n",
        "# - Ratio fraudes/légitimes\n",
        "\n",
        "legit_count = df[df['Class'] == 0].shape[0]\n",
        "fraud_count = df[df['Class'] == 1].shape[0]\n",
        "fraud_percentage = (fraud_count / len(df)) * 100\n",
        "\n",
        "print(f\"Transactions légitimes: {legit_count:,}\")\n",
        "print(f\"Fraudes: {fraud_count:,}\")\n",
        "print(f\"Pourcentage de fraudes: {fraud_percentage:.3f}%\")\n",
        "print(f\"Ratio (1 fraude pour X légitimes): 1:{legit_count/fraud_count:.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxzMP76AABOd"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualiser la distribution des classes avec un bar plot\n",
        "\n",
        "n_legit = legit_count\n",
        "n_fraud = fraud_count\n",
        "\n",
        "labels = ['Légitimes (0)', 'Fraudes (1)']\n",
        "values = [n_legit, n_fraud]\n",
        "colors = [\"#00F5A0\", \"#FF4D6D\"]\n",
        "\n",
        "total = n_legit + n_fraud\n",
        "percentages = [v / total * 100 for v in values]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,6), facecolor=\"#0E1117\")\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "for i, v in enumerate(values):\n",
        "    ax.bar(labels[i], v, color=colors[i], alpha=0.08, width=0.6)\n",
        "    ax.bar(labels[i], v, color=colors[i], alpha=0.15, width=0.5)\n",
        "\n",
        "bars = ax.bar(labels, values, color=colors, width=0.4)\n",
        "\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width()/2,\n",
        "        height,\n",
        "        f\"{values[i]:,}\\n({percentages[i]:.2f}%)\",\n",
        "        ha='center',\n",
        "        va='bottom',\n",
        "        color=\"white\",\n",
        "        fontsize=11,\n",
        "        weight=\"bold\"\n",
        "    )\n",
        "\n",
        "ax.set_title(\n",
        "    \"Distribution des Classes — Transactions vs Fraudes\",\n",
        "    fontsize=15,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "ax.set_xlabel(\"Classe\", color=\"#C9D1D9\")\n",
        "ax.set_ylabel(\"Nombre de transactions\", color=\"#C9D1D9\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.grid(axis='y', linestyle=\"--\", alpha=0.08)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DlFurmHABOe"
      },
      "source": [
        "### QUESTION 1\n",
        "**Analysez les résultats ci-dessus et répondez :**\n",
        "\n",
        "1. Quel est le ratio fraudes/légitimes ? Est-ce un déséquilibre important ?\n",
        "2. Pourquoi ce déséquilibre est-il un problème pour le Machine Learning ?\n",
        "3. Quelles techniques pouvez-vous utiliser pour gérer ce déséquilibre ?\n",
        "\n",
        "**Vos réponses :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9H7RTqtABOe"
      },
      "source": [
        "```\n",
        "1. 0.173% de fraudes.\n",
        "\n",
        "2. Le modèle peut ignorer la fraude ou le modèle peut avoir une mauvaise detection de la classe fraude.\n",
        "\n",
        "3. mettre à niveau les données (Oversampling ou undersampling) ou rajouté des poids par classe dans le modèle.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx6usq3KABOe"
      },
      "source": [
        "### 1.3 Analyse des Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE85pZZOABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Comparer les statistiques (mean, std, min, max) pour Amount et Time\n",
        "# entre fraudes et transactions légitimes\n",
        "\n",
        "\n",
        "legit_count = df[df['Class'] == 0]\n",
        "fraud_count = df[df['Class'] == 1]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TRANSACTIONS LÉGITIMES\")\n",
        "print(\"=\"*60)\n",
        "print(legit_count[['Amount', 'Time']].agg(['mean', 'std', 'min', 'max']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FRAUDES\")\n",
        "print(\"=\"*60)\n",
        "print(fraud_count[['Amount', 'Time']].agg(['mean', 'std', 'min', 'max']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AyNzlQlABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer 2 histogrammes côte à côte pour visualiser la distribution de Amount\n",
        "# Un pour les légitimes, un pour les fraudes\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6), facecolor=\"#0E1117\")\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "counts, bins, patches = ax.hist(\n",
        "    legit_count['Amount'],\n",
        "    bins=50,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "for p in patches:\n",
        "    p.set_facecolor(\"#00F5A0\")\n",
        "    p.set_edgecolor(\"#00F5A0\")\n",
        "    p.set_alpha(0.5)\n",
        "\n",
        "ax.set_title(\n",
        "    \"Distribution des Montants — Transactions Légitimes\",\n",
        "    fontsize=15,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "ax.set_xlabel(\"Montant\", color=\"#C9D1D9\")\n",
        "ax.set_ylabel(\"Fréquence\", color=\"#C9D1D9\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.set_yscale(\"log\")\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.08)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ===============================\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6), facecolor=\"#0E1117\")\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "counts, bins, patches = ax.hist(\n",
        "    fraud_count['Amount'],\n",
        "    bins=50,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "for p in patches:\n",
        "    p.set_facecolor(\"#FF4D6D\")\n",
        "    p.set_edgecolor(\"#FF4D6D\")\n",
        "    p.set_alpha(0.5)\n",
        "\n",
        "ax.set_title(\n",
        "    \"Distribution des Montants — Fraudes\",\n",
        "    fontsize=15,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "ax.set_xlabel(\"Montant\", color=\"#C9D1D9\")\n",
        "ax.set_ylabel(\"Fréquence\", color=\"#C9D1D9\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.set_yscale(\"log\")\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.08)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtiG8DSEABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des boxplots pour comparer Amount entre fraudes et légitimes\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6), facecolor=\"#0E1117\")\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "data = [legit_count['Amount'], fraud_count['Amount']]\n",
        "\n",
        "box = ax.boxplot(\n",
        "    data,\n",
        "    patch_artist=True,\n",
        "    labels=['Légitime', 'Fraude'],\n",
        "    showfliers=True,\n",
        "    medianprops=dict(color=\"white\", linewidth=2),\n",
        "    whiskerprops=dict(color=\"#C9D1D9\"),\n",
        "    capprops=dict(color=\"#C9D1D9\")\n",
        ")\n",
        "\n",
        "colors = [\"#00F5A0\", \"#FF4D6D\"]\n",
        "\n",
        "for patch, color in zip(box['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.6)\n",
        "    patch.set_edgecolor(color)\n",
        "\n",
        "for flier, color in zip(box['fliers'], colors):\n",
        "    flier.set(marker='o',\n",
        "              markerfacecolor=color,\n",
        "              markeredgecolor=color,\n",
        "              alpha=0.3)\n",
        "\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "\n",
        "ax.set_title(\n",
        "    \"Distribution des Montants — Légitime vs Fraude (échelle log)\",\n",
        "    fontsize=15,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "ax.set_ylabel(\"Montant (log scale)\", color=\"#C9D1D9\")\n",
        "ax.set_yscale('log')\n",
        "\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.08)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHQg-htsABOe"
      },
      "source": [
        "### 1.4 Analyse de Corrélation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sypAk6zABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculer la corrélation de toutes les features avec 'Class'\n",
        "# Afficher les 10 features les plus corrélées\n",
        "\n",
        "correlations = df.corr()['Class']\n",
        "\n",
        "# Sélection des 10 features les plus corrélées\n",
        "top_10 = correlations.sort_values(ascending=False).head(10)\n",
        "top_10_corr = top_10.index\n",
        "\n",
        "# Affichage\n",
        "print(\"Top 10 Features corrélées avec Class:\")\n",
        "print(top_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KInJZH2nABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer une heatmap des 10 features les plus corrélées avec Class\n",
        "\n",
        "corr_matrix = df[top_10_corr].corr()\n",
        "\n",
        "plt.figure(figsize=(11, 9), facecolor=\"#0E1117\")\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "heatmap = sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"icefire\",\n",
        "    center=0,\n",
        "    linewidths=0.5,\n",
        "    linecolor=\"#1C1F26\",\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "\n",
        "plt.title(\n",
        "    \"Heatmap — Top 10 Features Corrélées avec 'Class'\",\n",
        "    fontsize=16,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "plt.xticks(rotation=45, ha=\"right\", color=\"#C9D1D9\")\n",
        "plt.yticks(color=\"#C9D1D9\")\n",
        "\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.ax.yaxis.set_tick_params(color=\"#C9D1D9\")\n",
        "plt.setp(cbar.ax.get_yticklabels(), color=\"#C9D1D9\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMHwyTGIABOe"
      },
      "source": [
        "### QUESTION 2\n",
        "**Analysez les corrélations :**\n",
        "\n",
        "1. Quelles sont les 3 features PCA les plus corrélées avec Class ?\n",
        "2. Les fraudes ont-elles des montants typiques différents des transactions légitimes ?\n",
        "3. Y a-t-il des patterns temporels visibles ?\n",
        "\n",
        "**Vos réponses :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuLD77JNABOe"
      },
      "source": [
        "```\n",
        "1. Les 3 features les plus corrélées avec class sont : V11(0,15), V4(0,13) et V2(0,09)\n",
        "\n",
        "2. Les fraudes ont globalement des montants plus faible que les transactions légitimes\n",
        "\n",
        "3. Non\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA-rZyYWABOe"
      },
      "source": [
        "### 1.4bis Analyse Temporelle Approfondie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZIhuIAbABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Analyser la distribution des fraudes par heure\n",
        "# Créer un graphique montrant le nombre de fraudes par heure\n",
        "# Comparer avec les transactions légitimes\n",
        "\n",
        "\n",
        "df['Hour'] = (df['Time'] // 3600) % 24\n",
        "\n",
        "transactions_per_hour = df.groupby('Hour').size()\n",
        "\n",
        "fraud_df = df[df['Class'] == 1]\n",
        "legit_df = df[df['Class'] == 0]\n",
        "\n",
        "fraud_by_hour = fraud_df.groupby('Hour').size()\n",
        "legit_by_hour = legit_df.groupby('Hour').size()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14,7), facecolor=\"#0E1117\")\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "ax.axvspan(0, 6, color='#1C1F26', alpha=0.4)\n",
        "ax.axvspan(6, 18, color='#F5F7FA', alpha=0.05)\n",
        "ax.axvspan(18, 24, color='#1C1F26', alpha=0.4)\n",
        "\n",
        "x_legit = legit_by_hour.index\n",
        "y_legit = legit_by_hour.values\n",
        "\n",
        "for lw, alpha in [(10,0.03),(7,0.06),(5,0.12)]:\n",
        "    ax.plot(x_legit, y_legit, color=\"#00F5A0\", linewidth=lw, alpha=alpha)\n",
        "\n",
        "ax.plot(x_legit, y_legit,\n",
        "        marker='o',\n",
        "        markersize=6,\n",
        "        linewidth=2.5,\n",
        "        color=\"#00F5A0\",\n",
        "        label=\"Transactions légitimes\")\n",
        "\n",
        "x_fraud = fraud_by_hour.index\n",
        "y_fraud = fraud_by_hour.values\n",
        "\n",
        "for lw, alpha in [(10,0.03),(7,0.06),(5,0.12)]:\n",
        "    ax.plot(x_fraud, y_fraud, color=\"#FF4D6D\", linewidth=lw, alpha=alpha)\n",
        "\n",
        "ax.plot(x_fraud, y_fraud,\n",
        "        marker='o',\n",
        "        markersize=6,\n",
        "        linewidth=2.5,\n",
        "        color=\"#FF4D6D\",\n",
        "        label=\"Fraudes\")\n",
        "\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "ax.set_xticks(range(0,24))\n",
        "\n",
        "ax.set_xlabel(\"Heure de la journée\", color=\"#C9D1D9\", fontsize=12)\n",
        "ax.set_ylabel(\"Nombre de transactions\", color=\"#C9D1D9\", fontsize=12)\n",
        "\n",
        "ax.set_title(\"Transactions légitimes vs Fraudes — Analyse Horaire\",\n",
        "             fontsize=16, color=\"white\", pad=20, weight=\"bold\")\n",
        "\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.08)\n",
        "\n",
        "leg = ax.legend(facecolor=\"#1C1F26\", edgecolor=\"none\")\n",
        "for text in leg.get_texts():\n",
        "    text.set_color(\"white\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FywgEYGrABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Analyser les patterns jour/nuit\n",
        "# Calculer le taux de fraude pour chaque heure\n",
        "# Formule: taux_fraude(h) = nb_fraudes(h) / nb_total_transactions(h)\n",
        "# Identifier les heures à risque élevé\n",
        "\n",
        "fraud_rate_per_hour = (fraud_by_hour / transactions_per_hour).fillna(0)\n",
        "\n",
        "seuil = fraud_rate_per_hour.mean() + fraud_rate_per_hour.std()\n",
        "high_risk_hours = fraud_rate_per_hour[fraud_rate_per_hour > seuil]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14,7), facecolor=\"#0E1117\")\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "ax.axvspan(0, 6, color='#1C1F26', alpha=0.4)\n",
        "ax.axvspan(6, 18, color='#F5F7FA', alpha=0.05)\n",
        "ax.axvspan(18, 24, color='#1C1F26', alpha=0.4)\n",
        "\n",
        "x = fraud_rate_per_hour.index\n",
        "y = fraud_rate_per_hour.values\n",
        "\n",
        "for lw, alpha in [(8,0.05),(6,0.08),(4,0.15)]:\n",
        "    ax.plot(x, y, color=\"#FF4D6D\", linewidth=lw, alpha=alpha)\n",
        "\n",
        "ax.plot(x, y, marker='o', markersize=6,\n",
        "        color=\"#FF4D6D\", linewidth=2.5,\n",
        "        label=\"Taux de fraude\")\n",
        "\n",
        "ax.fill_between(x, y, seuil, where=(y > seuil),\n",
        "                color=\"#FF4D6D\", alpha=0.25)\n",
        "\n",
        "ax.scatter(high_risk_hours.index,\n",
        "           high_risk_hours.values,\n",
        "           color=\"#FFD60A\",\n",
        "           s=120,\n",
        "           zorder=5,\n",
        "           label=\"Heure à risque\")\n",
        "\n",
        "ax.axhline(seuil, color=\"#00F5D4\",\n",
        "           linestyle=\"--\", linewidth=1.5,\n",
        "           label=\"Seuil risque élevé\")\n",
        "\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "ax.set_xticks(range(0,24))\n",
        "\n",
        "ax.set_xlabel(\"Heure de la journée\", color=\"#C9D1D9\", fontsize=12)\n",
        "ax.set_ylabel(\"Taux de fraude\", color=\"#C9D1D9\", fontsize=12)\n",
        "ax.set_title(\"Analyse Jour / Nuit — Détection des Heures à Risque\",\n",
        "             fontsize=16, color=\"white\", pad=20, weight=\"bold\")\n",
        "\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.1)\n",
        "\n",
        "ax.legend(facecolor=\"#1C1F26\", edgecolor=\"none\", labelcolor=\"white\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Heures à risque élevé :\", list(high_risk_hours.index))\n",
        "print(\"Taux de fraude élevé :\", list(high_risk_hours.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wc2TdUKABOe"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer une matrice de corrélation entre Time, Amount et les top 5 features PCA\n",
        "# Visualiser avec une heatmap\n",
        "\n",
        "top5_pca_cols = ['V1','V2','V3','V4','V5']\n",
        "df_corr = df[['Time', 'Amount'] + top5_pca_cols]\n",
        "\n",
        "corr_matrix = df_corr.corr()\n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "plt.figure(figsize=(11,9), facecolor=\"#0E1117\")\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "heatmap = sns.heatmap(\n",
        "    corr_matrix,\n",
        "    mask=mask,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"icefire\",\n",
        "    center=0,\n",
        "    linewidths=0.5,\n",
        "    linecolor=\"#1C1F26\",\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "\n",
        "plt.title(\n",
        "    \"Matrice de Corrélation — Time, Amount & Top 5 PCA (V1–V5)\",\n",
        "    fontsize=16,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "plt.xticks(rotation=45, ha=\"right\", color=\"#C9D1D9\")\n",
        "plt.yticks(color=\"#C9D1D9\")\n",
        "\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.ax.yaxis.set_tick_params(color=\"#C9D1D9\")\n",
        "plt.setp(cbar.ax.get_yticklabels(), color=\"#C9D1D9\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoXjel3NABOe"
      },
      "source": [
        "---\n",
        "### 1.5 Feature Engineering Avancé\n",
        "**Mission : Créer au minimum 15 nouvelles features pertinentes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygbGh3LqABOe"
      },
      "outputs": [],
      "source": [
        "# Créer une copie pour le feature engineering\n",
        "df_fe = df.copy()\n",
        "\n",
        "print(f\"Shape initiale: {df_fe.shape}\")\n",
        "df_fe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP3h_ET6ABOf"
      },
      "source": [
        "#### Features Temporelles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPJ3ysE_ABOf"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer les features temporelles suivantes :\n",
        "# 1. 'hour' : Heure de la journée (0-23) à partir de Time\n",
        "# 2. 'day' : Jour (0 ou 1) à partir de Time\n",
        "# 3. 'hour_sin' : Encodage cyclique sin de l'heure\n",
        "# 4. 'hour_cos' : Encodage cyclique cos de l'heure\n",
        "\n",
        "df_fe['hour'] = (df_fe['Time'] // 3600) % 24\n",
        "df_fe['day'] = (df_fe['Time'] // (24*3600)) % 2\n",
        "df_fe['hour_sin'] = np.sin(2 * np.pi * df_fe['hour'] / 24)\n",
        "df_fe['hour_cos'] = np.cos(2 * np.pi * df_fe['hour'] / 24)\n",
        "\n",
        "print(\" Features temporelles créées\")\n",
        "df_fe[['Time', 'hour', 'day', 'hour_sin', 'hour_cos']].head()\n",
        "\n",
        "df_fe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sDgRpHhABOf"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer une feature 'period' (période de la journée)\n",
        "# Nuit: 0-6h, Matin: 6-12h, Après-midi: 12-18h, Soir: 18-24h\n",
        "\n",
        "def get_period(hour):\n",
        "    \"\"\"Retourne la période de la journée\"\"\"\n",
        "    if 0 <= hour < 6:\n",
        "        return 'Nuit'\n",
        "    elif 6 <= hour < 12:\n",
        "        return 'Matin'\n",
        "    elif 12 <= hour < 18:\n",
        "        return 'Après-midi'\n",
        "    elif 18 <= hour < 24:\n",
        "        return 'Soir'\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "df_fe['period'] = df_fe['hour'].apply(get_period)\n",
        "\n",
        "print(\"Distribution des périodes:\")\n",
        "print(df_fe['period'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_vgulybABOf"
      },
      "source": [
        "#### Features sur les Montants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvC2LN3BABOf"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer les features suivantes sur Amount :\n",
        "# 1. 'amount_log' : Log transformation (gérer l'asymétrie)\n",
        "# 2. 'amount_sqrt' : Racine carrée\n",
        "# 3. 'is_zero_amount' : Indicateur si montant = 0\n",
        "\n",
        "df_fe['amount_log'] = np.log1p(df_fe['Amount'])\n",
        "df_fe['amount_sqrt'] = np.sqrt(df_fe['Amount'])\n",
        "df_fe['is_zero_amount'] = (df_fe['Amount'] == 0).astype(int)\n",
        "\n",
        "print(\"Features sur montants créées\")\n",
        "df_fe[['Amount', 'amount_log', 'amount_sqrt', 'is_zero_amount']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDiEAJSCABOf"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer un binning du montant\n",
        "# Catégories suggérées: [0, 10, 50, 100, 500, inf]\n",
        "# Labels: ['micro', 'small', 'medium', 'large', 'xlarge']\n",
        "\n",
        "bins = [0, 10, 50, 100, 500, np.inf]\n",
        "labels = ['micro', 'small', 'medium', 'large', 'xlarge']\n",
        "\n",
        "df_fe['amount_bin'] = pd.cut(df_fe['Amount'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "print(\"Distribution des bins:\")\n",
        "print(df_fe['amount_bin'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sQ3v058ABOm"
      },
      "source": [
        "#### Features d'Interaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe46pt2QABOm"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des features d'interaction\n",
        "# Multiplier Amount avec les 3 features PCA les plus corrélées avec Class\n",
        "# (identifiées dans l'analyse de corrélation)\n",
        "# Exemple: df_fe['V1_amount'] = df_fe['V1'] * df_fe['Amount']\n",
        "\n",
        "df_fe['V2_amount'] = df_fe['V2'] * df_fe['Amount']\n",
        "df_fe['V4_amount'] = df_fe['V4'] * df_fe['Amount']\n",
        "df_fe['V7_amount'] = df_fe['V7'] * df_fe['Amount']\n",
        "\n",
        "print(\"Features d'interaction créées\")\n",
        "df_fe[['Amount', 'V2', 'V2_amount', 'V4', 'V4_amount', 'V7', 'V7_amount']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgNsqXHdABOm"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des features d'agrégation sur les V1-V28\n",
        "# Exemples:\n",
        "# - Somme des 5 premières features PCA\n",
        "# - Moyenne des 5 premières features PCA\n",
        "# - Écart-type des features PCA\n",
        "\n",
        "pca_cols = [f'V{i}' for i in range(1, 29)]\n",
        "\n",
        "df_fe['V1_5_sum'] = df_fe[pca_cols[:5]].sum(axis=1)\n",
        "\n",
        "df_fe['V1_5_mean'] = df_fe[pca_cols[:5]].mean(axis=1)\n",
        "\n",
        "df_fe['V1_28_std'] = df_fe[pca_cols].std(axis=1)\n",
        "\n",
        "df_fe['V1_28_median'] = df_fe[pca_cols].median(axis=1)\n",
        "\n",
        "print(\"Features d'agrégation créées\")\n",
        "df_fe[['V1_5_sum', 'V1_5_mean', 'V1_28_std', 'V1_28_median']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIhC39TZABOm"
      },
      "source": [
        "#### Features Polynomiales et Ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNeBSWz1ABOm"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des features polynomiales\n",
        "# 1. amount_squared = Amount²\n",
        "# 2. amount_cubed = Amount³\n",
        "# Justification: Capturer les relations non-linéaires\n",
        "\n",
        "df_fe['amount_squared'] = df_fe['Amount'] ** 2\n",
        "df_fe['amount_cubed'] = df_fe['Amount'] ** 3\n",
        "\n",
        "print(\"Features polynomiales créées\")\n",
        "df_fe[['Amount', 'amount_squared', 'amount_cubed']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M10StYq7ABOm"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des features de ratio\n",
        "# 1. amount_per_hour = Amount / (hour + 1) pour éviter division par 0\n",
        "# 2. time_amount_ratio = Time / (Amount + 1)\n",
        "# Justification: Relations entre variables temporelles et montants\n",
        "\n",
        "df_fe['amount_per_hour'] = df_fe['Amount'] / (df_fe['hour'] + 1)\n",
        "df_fe['time_amount_ratio'] = df_fe['Time'] / (df_fe['Amount'] + 1)\n",
        "\n",
        "print(\"Features de ratio créées\")\n",
        "df_fe[['Amount', 'hour', 'amount_per_hour', 'Time', 'time_amount_ratio']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_6vn97nABOn"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des features d'écart à la moyenne\n",
        "# Pour les 3 features PCA les plus corrélées, calculer:\n",
        "# deviation_Vi = |Vi - mean(Vi)| / std(Vi)\n",
        "# Justification: Identifier les valeurs anormales (z-score absolu)\n",
        "\n",
        "top3_pca = ['V11', 'V4', 'V2']\n",
        "\n",
        "for col in top3_pca:\n",
        "    mean_val = df_fe[col].mean()\n",
        "    std_val = df_fe[col].std()\n",
        "    df_fe[f'deviation_{col}'] = np.abs(df_fe[col] - mean_val) / std_val\n",
        "\n",
        "print(\"Features d'écart créées\")\n",
        "df_fe[[f'deviation_{col}' for col in top3_pca]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZxEo4ToABOn"
      },
      "source": [
        "#### Validation des Nouvelles Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWjazMaLABOn"
      },
      "outputs": [],
      "source": [
        "# Compter les nouvelles features créées\n",
        "original_features = df.shape[1]\n",
        "new_features_count = df_fe.shape[1] - original_features\n",
        "\n",
        "print(f\"Features originales: {original_features}\")\n",
        "print(f\"Nouvelles features créées: {new_features_count}\")\n",
        "print(f\"Total features: {df_fe.shape[1]}\")\n",
        "\n",
        "# Lister les nouvelles features\n",
        "new_features = [col for col in df_fe.columns if col not in df.columns]\n",
        "print(f\"\\nNouvelles features: {new_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCYY_DphABOn"
      },
      "outputs": [],
      "source": [
        "# TODO: Analyser la corrélation des nouvelles features avec Class\n",
        "# Afficher les nouvelles features triées par corrélation absolue\n",
        "\n",
        "original_cols = [f'V{i}' for i in range(1,29)] + ['Time','Amount','Class']\n",
        "new_features = [col for col in df_fe.columns if col not in original_cols and col not in ['period', 'amount_bin']]\n",
        "\n",
        "corr_with_class = df_fe[new_features + ['Class']].corr()['Class'].drop('Class')\n",
        "\n",
        "corr_sorted = corr_with_class.reindex(corr_with_class.abs().sort_values(ascending=False).index)\n",
        "\n",
        "print(\"Corrélation des nouvelles features avec Class :\")\n",
        "print(corr_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psv86LUNABOn"
      },
      "source": [
        "### QUESTION 3\n",
        "**Justifiez vos choix de Feature Engineering :**\n",
        "\n",
        "1. Quelles features créées sont les plus prometteuses (corrélation) ?\n",
        "2. Pourquoi l'encodage cyclique (sin/cos) est-il pertinent pour l'heure ?\n",
        "3. Quel est l'intérêt métier de créer des interactions Amount × V_i ?\n",
        "\n",
        "**Vos réponses :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZNKT1IHABOn"
      },
      "source": [
        "```\n",
        "1. V1_28_std, deviation_V11, deviation_V4, V1_28_median, deviation_V2\n",
        "\n",
        "2. pour que 22H soit plus proche de 2H\n",
        "\n",
        "3. pour detecter les montants élevé combiner aux features PCA inhabituelle, qui normalement sont plus suspect\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hujXbc0wABOn"
      },
      "source": [
        "---\n",
        "## PARTIE 2 : MODÉLISATION BASELINE (1h30)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2YWbNYuABOn"
      },
      "source": [
        "### 2.1 Préparation des Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLJhYu7jABOn"
      },
      "outputs": [],
      "source": [
        "# TODO: Séparer X et y\n",
        "# Attention: Exclure les colonnes catégorielles non encodées (ex: 'period', 'amount_bin')\n",
        "# ou les encoder avant avec pd.get_dummies()\n",
        "\n",
        "# Encoder les variables catégorielles si nécessaire\n",
        "# df_fe_encoded = pd.get_dummies(df_fe, columns=['period', 'amount_bin'], drop_first=True)\n",
        "\n",
        "exclude_cols = ['Class', 'period', 'amount_bin']\n",
        "X = df_fe.drop(columns=exclude_cols)\n",
        "y = df_fe['Class']\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JWWCRFaABOn"
      },
      "outputs": [],
      "source": [
        "# TODO: Split Train/Test\n",
        "# Utiliser stratify=y pour préserver le ratio des classes\n",
        "# Test size: 20%\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "print(f\"\\nDistribution dans le train:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"\\nDistribution dans le test:\")\n",
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFwzwxy0ABOn"
      },
      "outputs": [],
      "source": [
        "# TODO: Scaling\n",
        "# Choisir entre StandardScaler ou RobustScaler\n",
        "# RobustScaler est recommandé car il gère mieux les outliers\n",
        "\n",
        "scaler = RobustScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Scaling effectué\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85yhMsABOn"
      },
      "source": [
        "### QUESTION 4\n",
        "**Justifiez votre choix de scaler :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lql7IRs6ABOo"
      },
      "source": [
        "```\n",
        "J'ai choisi [StandardScaler/RobustScaler] parce que Certaines features comme Amount et les agrégations PCA (V1_28_std, V1_28_median, etc.) contiennent des valeurs extrêmes.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCaq-sFxABOo"
      },
      "source": [
        "### 2.2 Modèles Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZA7AvwXABOo"
      },
      "outputs": [],
      "source": [
        "# Fonction utilitaire pour évaluer un modèle\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Entraîne et évalue un modèle\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionnaire avec les métriques\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ÉVALUATION: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        y_proba = model.decision_function(X_test)\n",
        "    else:\n",
        "        y_proba = y_pred\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "    pr_auc = average_precision_score(y_test, y_proba)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(f\"Precision : {precision:.4f}\")\n",
        "    print(f\"Recall    : {recall:.4f}\")\n",
        "    print(f\"F1-score  : {f1:.4f}\")\n",
        "    print(f\"ROC-AUC   : {roc_auc:.4f}\")\n",
        "    print(f\"PR-AUC    : {pr_auc:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "print(\"Fonction d'évaluation créée\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw79YtqlABOo"
      },
      "source": [
        "#### Modèle 1 : Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiWj_334ABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer et évaluer une Logistic Regression\n",
        "# Utiliser class_weight='balanced' pour gérer le déséquilibre\n",
        "\n",
        "lr_model = LogisticRegression(\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Évaluer le modèle\n",
        "lr_results = evaluate_model(\n",
        "    lr_model,\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"Logistic Regression\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNRu8WZrABOo"
      },
      "source": [
        "#### Modèle 2 : Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWZllIaVABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer et évaluer un Decision Tree\n",
        "# Paramètres suggérés: max_depth=10, class_weight='balanced'\n",
        "\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=10,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt_results = evaluate_model(\n",
        "    dt_model,\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"Decision Tree\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgYJzvVCABOo"
      },
      "source": [
        "#### Modèle 3 : Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXOmXl3bABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer et évaluer un Random Forest\n",
        "# Paramètres suggérés: n_estimators=100, class_weight='balanced'\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Évaluer le modèle\n",
        "rf_results = evaluate_model(\n",
        "    rf_model,\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"Random Forest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt91w1oCABOo"
      },
      "source": [
        "#### Modèle 4 : Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Bm4ytJkABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer et évaluer un SVM\n",
        "# Paramètres: kernel='rbf', class_weight='balanced', C=1.0\n",
        "# Note: SVM peut être lent sur de grandes données\n",
        "\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',\n",
        "    class_weight='balanced',\n",
        "    C=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_results = evaluate_model(\n",
        "    svm_model,\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"SVM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYHpedRgABOo"
      },
      "source": [
        "#### Modèle 5 : K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_U278MtABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer et évaluer un KNN\n",
        "# Paramètres: n_neighbors=5, weights='distance'\n",
        "# Note: KNN nécessite des données scalées\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(\n",
        "    n_neighbors=5,\n",
        "    weights='distance',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "knn_results = evaluate_model(\n",
        "    knn_model,\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"KNN\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GOwhqzAABOo"
      },
      "source": [
        "#### Modèle 6 : XGBoost (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1NJr2Q5ABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer et évaluer un XGBoost baseline\n",
        "# Paramètres: n_estimators=100, max_depth=5, learning_rate=0.1\n",
        "# scale_pos_weight = nb_negatifs / nb_positifs (pour gérer le déséquilibre)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_results = evaluate_model(\n",
        "    xgb_model,\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"XGBoost\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8cWMFZjABOo"
      },
      "source": [
        "### 2.3 Comparaison des Modèles Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtGevTBnABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer un tableau comparatif des 6 modèles\n",
        "# Colonnes: Model, Precision, Recall, F1, ROC-AUC, PR-AUC\n",
        "# pd.DataFrame([lr_results, dt_results, rf_results, svm_results, knn_results, xgb_results])\n",
        "\n",
        "results_list = [\n",
        "    {\"Model\": \"Logistic Regression\", **lr_results},\n",
        "    {\"Model\": \"Decision Tree\", **dt_results},\n",
        "    {\"Model\": \"Random Forest\", **rf_results},\n",
        "    {\"Model\": \"KNN\", **knn_results},\n",
        "    {\"Model\": \"XGBoost\", **xgb_results}\n",
        "]\n",
        "\n",
        "comparison_df = pd.DataFrame(results_list)\n",
        "\n",
        "comparison_df = comparison_df[[\"Model\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\", \"pr_auc\"]]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARAISON DES MODÈLES BASELINE\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwksL9lRABOo"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualiser la comparaison avec un bar plot\n",
        "# Afficher Precision, Recall, F1, PR-AUC pour les 3 modèles\n",
        "\n",
        "top_models = comparison_df[comparison_df['Model'].isin([\n",
        "    \"Logistic Regression\", \"Random Forest\", \"XGBoost\"\n",
        "])]\n",
        "\n",
        "plot_data = top_models.melt(\n",
        "    id_vars='Model',\n",
        "    value_vars=['precision', 'recall', 'f1_score', 'pr_auc'],\n",
        "    var_name='Metric',\n",
        "    value_name='Score'\n",
        ")\n",
        "\n",
        "metric_colors = {\n",
        "    'precision': \"#00F5A0\",\n",
        "    'recall': \"#FFD60A\",\n",
        "    'f1_score': \"#FF4D6D\",\n",
        "    'pr_auc': \"#4CC9F0\"\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(11,6), facecolor=\"#0E1117\")\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(\"#0E1117\")\n",
        "\n",
        "sns.barplot(\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    hue='Metric',\n",
        "    data=plot_data,\n",
        "    palette=metric_colors,\n",
        "    edgecolor=\"white\",\n",
        "    alpha=0.85\n",
        ")\n",
        "\n",
        "plt.ylim(0,1)\n",
        "plt.title(\n",
        "    \"Comparaison des Métriques — Modèles Baseline\",\n",
        "    fontsize=16,\n",
        "    color=\"white\",\n",
        "    pad=20,\n",
        "    weight=\"bold\"\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Modèle\", color=\"#C9D1D9\")\n",
        "plt.ylabel(\"Score\", color=\"#C9D1D9\")\n",
        "\n",
        "ax.tick_params(colors=\"#C9D1D9\")\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color(\"#2A2F3A\")\n",
        "ax.spines['bottom'].set_color(\"#2A2F3A\")\n",
        "\n",
        "ax.grid(axis='y', linestyle=\"--\", alpha=0.08)\n",
        "\n",
        "leg = ax.legend(title='Métrique', facecolor=\"#1C1F26\", edgecolor=\"none\")\n",
        "for text in leg.get_texts():\n",
        "    text.set_color(\"white\")\n",
        "leg.get_title().set_color(\"white\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aosqKI_yABOp"
      },
      "source": [
        "### 2.4 Comparaison des Stratégies de Rééquilibrage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTU8YG1HABOp"
      },
      "outputs": [],
      "source": [
        "# TODO: Comparer class_weight='balanced' vs SMOTE\n",
        "# Prendre le meilleur modèle baseline et tester avec SMOTE\n",
        "# Formule SMOTE: Génère des exemples synthétiques pour la classe minoritaire\n",
        "# Pour chaque exemple minoritaire x_i, choisir k voisins et créer:\n",
        "# x_new = x_i + λ * (x_neighbor - x_i) où λ ∈ [0,1]\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "smote = SMOTE(random_state=RANDOM_STATE)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Avant SMOTE: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"Après SMOTE: {pd.Series(y_train_smote).value_counts().to_dict()}\")\n",
        "\n",
        "xgb_smote_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "xgb_smote_results = evaluate_model(\n",
        "    xgb_smote_model,\n",
        "    X_train_smote,\n",
        "    X_test_scaled,\n",
        "    y_train_smote,\n",
        "    y_test,\n",
        "    model_name=\"XGBoost + SMOTE\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nygD0loDABOp"
      },
      "outputs": [],
      "source": [
        "# TODO: Comparer les résultats\n",
        "# Créer un tableau: Stratégie | Precision | Recall | F1 | PR-AUC\n",
        "# Ligne 1: class_weight='balanced'\n",
        "# Ligne 2: SMOTE\n",
        "# Analyser quelle stratégie est la plus efficace\n",
        "\n",
        "comparison_strategy_df = pd.DataFrame([\n",
        "    {\n",
        "        \"Stratégie\": \"Class Weight = 'balanced'\",\n",
        "        \"Precision\": xgb_results['precision'],\n",
        "        \"Recall\": xgb_results['recall'],\n",
        "        \"F1\": xgb_results['f1_score'],\n",
        "        \"PR-AUC\": xgb_results['pr_auc']\n",
        "    },\n",
        "    {\n",
        "        \"Stratégie\": \"SMOTE\",\n",
        "        \"Precision\": xgb_smote_results['precision'],\n",
        "        \"Recall\": xgb_smote_results['recall'],\n",
        "        \"F1\": xgb_smote_results['f1_score'],\n",
        "        \"PR-AUC\": xgb_smote_results['pr_auc']\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARAISON DES STRATÉGIES D'ÉQUILIBRAGE\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_strategy_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpfa15bmABOp"
      },
      "source": [
        "### QUESTION 5\n",
        "**Analysez les résultats baseline :**\n",
        "\n",
        "1. Parmi les 6 modèles testés, lequel a le meilleur Recall ? Est-ce suffisant (objectif ≥ 0.85) ?\n",
        "2. Pourquoi PR-AUC est-il plus pertinent que ROC-AUC ici ?\n",
        "3. Comparez class_weight vs SMOTE. Quelle stratégie est la plus efficace ?\n",
        "4. Quel modèle choisiriez-vous pour l'optimisation ? Pourquoi ?\n",
        "\n",
        "**Vos réponses :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soImHTVcABOp"
      },
      "source": [
        "```\n",
        "1. le model de Logistic Regression, oui (0,9)\n",
        "\n",
        "2. car on a des données déséquilibré\n",
        "\n",
        "3. le plus efficace est le class_weight avec une meilleur Precision et F1\n",
        "\n",
        "4. le model de Random Forest car il a le meilleur compromis entre Précision (0,9) et Recall (0,75)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76jGJuISABOp"
      },
      "source": [
        "---\n",
        "## PARTIE 3 : OPTIMISATION AVANCÉE (2h)\n",
        "---\n",
        "\n",
        "**Note** : Cette partie peut prendre du temps (GridSearch = 15-30 min). Commencez par une petite grille pour tester !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoLDvQkxABOp"
      },
      "source": [
        "### 3.1 Construction d'un Pipeline ML Complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNfPsVpyABOp"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer un Pipeline intégrant:\n",
        "# 1. Scaling (RobustScaler)\n",
        "# 2. Modèle (Random Forest - le meilleur baseline)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', RobustScaler()),\n",
        "    ('rf', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(\"Pipeline créé\")\n",
        "print(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkMH3YwlABOp"
      },
      "source": [
        "### 3.2 Optimisation Hyperparamètres - GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLaidY4nABOp"
      },
      "outputs": [],
      "source": [
        "# TODO: Définir une grille de paramètres pour Random Forest\n",
        "# IMPORTANT: Préfixer les paramètres avec 'classifier__' car dans un pipeline\n",
        "# Commencez PETIT pour tester (2-3 valeurs par paramètre max)\n",
        "# Exemple:\n",
        "# param_grid = {\n",
        "# 'classifier__n_estimators': [100, 200],\n",
        "# 'classifier__max_depth': [10, None],\n",
        "# 'classifier__min_samples_split': [2, 5],\n",
        "# 'classifier__class_weight': ['balanced']\n",
        "# }\n",
        "\n",
        "param_grid = {\n",
        "    'rf__n_estimators': [100, 200],\n",
        "    'rf__max_depth': [10, None],\n",
        "    'rf__min_samples_split': [2, 5],\n",
        "    'rf__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "n_combinations = np.prod([len(v) for v in param_grid.values()])\n",
        "print(f\"Nombre de combinaisons: {n_combinations}\")\n",
        "print(f\"Avec cv=5 → {n_combinations * 5} entraînements\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6EIdN1qABOp"
      },
      "outputs": [],
      "source": [
        "# TODO: Configurer GridSearchCV\n",
        "# - cv: StratifiedKFold(n_splits=5)\n",
        "# - scoring: 'average_precision' (PR-AUC)\n",
        "# - n_jobs: -1 (parallélisation)\n",
        "# - verbose: 2 (afficher la progression)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='average_precision',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\" GridSearchCV configuré\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-D5hxWfABOp"
      },
      "outputs": [],
      "source": [
        "# TODO: Lancer la recherche (peut prendre plusieurs minutes)\n",
        "# Utiliser X_train et y_train (NON scalés, le pipeline s'en occupe)\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTemps d'exécution: {(end_time - start_time) / 60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK9I09CPABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Afficher les résultats de GridSearch\n",
        "# - Meilleurs paramètres (grid_search.best_params_)\n",
        "# - Meilleur score CV (grid_search.best_score_)\n",
        "# - Évaluer sur le test set (grid_search.best_estimator_)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RÉSULTATS GRIDSEARCH\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"Meilleurs paramètres trouvés :\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(f\"\\nMeilleur score cross-validation (PR-AUC) : {grid_search.best_score_:.4f}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_results = evaluate_model(\n",
        "    best_model,\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model_name=\"Random Forest Optimisé\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IBBJhg7ABOq"
      },
      "source": [
        "### 3.3 Optimisation avec RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNmvEguKABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Comparer GridSearchCV vs RandomizedSearchCV\n",
        "# RandomizedSearchCV teste n_iter combinaisons aléatoires au lieu de toutes\n",
        "# Avantage: Plus rapide, peut explorer un espace plus large\n",
        "# Formule: Probabilité de trouver le top 5% en testant n combinaisons aléatoires:\n",
        "# P = 1 - (0.95)^n\n",
        "# Exemple: n=20 → P ≈ 64%, n=60 → P ≈ 95%\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Définir des distributions de paramètres (plus larges que GridSearch)\n",
        "param_distributions = {\n",
        "    'rf__n_estimators': randint(50, 300),\n",
        "    'rf__max_depth': [5, 10, 15, 20, 25, None],\n",
        "    'rf__min_samples_split': randint(2, 20),\n",
        "    'rf__min_samples_leaf': randint(1, 10),\n",
        "    'rf__max_features': ['sqrt', 'log2', None],\n",
        "    'rf__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "# Configurer RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions,\n",
        "    n_iter=30,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "    scoring='average_precision',\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV configuré\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd9ZpYXwABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Lancer RandomizedSearchCV\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTemps d'exécution: {(end_time - start_time) / 60:.2f} minutes\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RÉSULTATS RANDOMIZEDSEARCH\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Meilleurs paramètres: {random_search.best_params_}\")\n",
        "print(f\"Meilleur score (CV - PR-AUC): {random_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65fGIl_nABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Comparer GridSearch vs RandomizedSearch\n",
        "# Créer un tableau comparatif:\n",
        "# Méthode | Meilleur Score | Temps (min) | Nb Combinaisons Testées\n",
        "\n",
        "comparaison_search = pd.DataFrame({\n",
        "    'Méthode': ['GridSearchCV', 'RandomizedSearchCV'],\n",
        "    'Meilleur_Score': [grid_score, random_score],\n",
        "    'Temps_min': [grid_time_min, random_time_min],\n",
        "    'Nb_Combinaisons': [grid_combinations, random_combinations]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARAISON DES MÉTHODES D'OPTIMISATION\")\n",
        "print(\"=\"*60)\n",
        "print(comparaison_search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LPAiA0LABOq"
      },
      "source": [
        "### 3.4 Optimisation de XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyPRrgnZABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Optimiser XGBoost avec RandomizedSearchCV\n",
        "# Créer un pipeline avec XGBoost\n",
        "# Paramètres à optimiser:\n",
        "# - n_estimators: [50, 100, 200, 300]\n",
        "# - max_depth: [3, 5, 7, 9]\n",
        "# - learning_rate: [0.01, 0.05, 0.1, 0.3]\n",
        "# - subsample: [0.6, 0.8, 1.0]\n",
        "# - colsample_bytree: [0.6, 0.8, 1.0]\n",
        "# - scale_pos_weight: calculé automatiquement\n",
        "\n",
        "pipeline_xgb = Pipeline([\n",
        "    ('scaler', RobustScaler()),\n",
        "    ('classifier', XGBClassifier(\n",
        "        random_state=42, \n",
        "        eval_metric='logloss',\n",
        "        use_label_encoder=False,\n",
        "        scale_pos_weight=scale_pos_weight\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    'classifier__n_estimators': [50, 100, 200, 300],\n",
        "    'classifier__max_depth': [3, 5, 7, 9],\n",
        "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
        "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
        "    'classifier__colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    pipeline_xgb,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=30,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Meilleurs paramètres :\", random_search_xgb.best_params_)\n",
        "print(\"Meilleur score ROC-AUC :\", random_search_xgb.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od9mPvn7ABOq"
      },
      "source": [
        "### QUESTION 6\n",
        "**Analysez l'optimisation :**\n",
        "\n",
        "1. Quels hyperparamètres ont le plus d'impact sur la performance ?\n",
        "2. Le gain de performance justifie-t-il le temps de calcul ?\n",
        "3. GridSearch vs RandomizedSearch: quelle méthode est la plus efficace ?\n",
        "4. XGBoost optimisé vs Random Forest optimisé: lequel est meilleur ?\n",
        "5. Atteignez-vous l'objectif de Recall ≥ 0.85 ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnOzxJ22ABOq"
      },
      "source": [
        "---\n",
        "## PARTIE 4 : ANALYSE & DIAGNOSTIC (1h)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w1U4ChbABOq"
      },
      "source": [
        "### 4.1 Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56SBM-BeABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Extraire l'importance des features du meilleur modèle\n",
        "\n",
        "feature_importances = best_model.feature_importances_\n",
        "\n",
        "df_features = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "df_features = df_features.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_15_features = df_features.head(15)\n",
        "print(top_15_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtJOG5NFABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualiser le Top 15 avec un bar plot horizontal\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x='Importance', \n",
        "    y='Feature', \n",
        "    data=top_15_features,\n",
        "    palette='viridis'\n",
        ")\n",
        "\n",
        "plt.title(\"Top 15 des features les plus importantes\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K64xr4Y7ABOq"
      },
      "source": [
        "### 4.1bis Permutation Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FLqL-I2ABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculer la Permutation Importance\n",
        "# Principe: Mélanger aléatoirement une feature et mesurer la baisse de performance\n",
        "# Formule: PI(f) = Score_original - Score_après_permutation(f)\n",
        "# Plus PI est élevé, plus la feature est importante\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "perm_importance = permutation_importance(\n",
        "    best_model,\n",
        "    X_test,\n",
        "    y_test,\n",
        "    n_repeats=10,\n",
        "    random_state=RANDOM_STATE,\n",
        "    scoring='average_precision'\n",
        ")\n",
        "\n",
        "perm_imp_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance_Mean': perm_importance.importances_mean,\n",
        "    'Importance_Std': perm_importance.importances_std\n",
        "}).sort_values('Importance_Mean', ascending=False)\n",
        "\n",
        "top15_perm = perm_imp_df.head(15)\n",
        "print(\"Top 15 Features - Permutation Importance:\")\n",
        "print(top15_perm)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x='Importance_Mean',\n",
        "    y='Feature',\n",
        "    data=top15_perm,\n",
        "    palette='magma',\n",
        "    xerr=top15_perm['Importance_Std']\n",
        ")\n",
        "plt.title(\"Top 15 Features par Permutation Importance\")\n",
        "plt.xlabel(\"Permutation Importance (mean ± std)\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_lg66GJABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Comparer MDI (Mean Decrease Impurity) vs Permutation Importance\n",
        "# Créer un graphique côte à côte\n",
        "# MDI peut être biaisé vers les features à haute cardinalité\n",
        "# Permutation Importance est plus fiable mais plus coûteux en calcul\n",
        "\n",
        "mdi_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False).head(15)\n",
        "mdi_df = mdi_df[::-1]\n",
        "\n",
        "perm_df = perm_imp_df.head(15)\n",
        "perm_df = perm_df[::-1]\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(14, 8), sharey=True)\n",
        "\n",
        "sns.barplot(\n",
        "    x='Importance',\n",
        "    y='Feature',\n",
        "    data=mdi_df,\n",
        "    ax=axes[0],\n",
        "    palette='viridis'\n",
        ")\n",
        "axes[0].set_title(\"Top 15 Features - MDI (Mean Decrease Impurity)\")\n",
        "axes[0].set_xlabel(\"Importance\")\n",
        "axes[0].set_ylabel(\"Feature\")\n",
        "\n",
        "sns.barplot(\n",
        "    x='Importance_Mean',\n",
        "    y='Feature',\n",
        "    data=perm_df,\n",
        "    ax=axes[1],\n",
        "    palette='magma',\n",
        "    xerr=perm_df['Importance_Std']\n",
        ")\n",
        "axes[1].set_title(\"Top 15 Features - Permutation Importance\")\n",
        "axes[1].set_xlabel(\"Importance (mean ± std)\")\n",
        "axes[1].set_ylabel(\"\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7aoceSfABOq"
      },
      "source": [
        "### 4.1ter SHAP Values (Explicabilité Avancée)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXFEx3hEABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculer les SHAP values\n",
        "# SHAP (SHapley Additive exPlanations) basé sur la théorie des jeux\n",
        "# Formule de Shapley: φ_i = Σ [|S|!(n-|S|-1)!/n!] × [f(S∪{i}) - f(S)]\n",
        "# où S sont tous les sous-ensembles de features sans i\n",
        "# Interprétation: Contribution marginale moyenne de chaque feature\n",
        "\n",
        "import shap\n",
        "\n",
        "explainer = shap.TreeExplainer(best_model.named_steps['classifier'])\n",
        "\n",
        "X_test_sample = X_test.iloc[:100]\n",
        "\n",
        "# 3️⃣ Calculer les SHAP values\n",
        "shap_values = explainer.shap_values(X_test_sample)\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    print(f\"SHAP values shape (class 1): {shap_values[1].shape}\")\n",
        "else:\n",
        "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values,\n",
        "                  X_test_sample,\n",
        "                  plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmtWS7GgABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualiser le summary plot SHAP\n",
        "# Ce graphique montre:\n",
        "# - L'importance de chaque feature (axe Y)\n",
        "# - L'impact sur la prédiction (axe X)\n",
        "# - La valeur de la feature (couleur: rouge=élevé, bleu=faible)\n",
        "\n",
        "shap_values_plot = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
        "\n",
        "shap.summary_plot(shap_values_plot, X_test_sample, plot_type=\"dot\", show=False)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tko3yisuABOq"
      },
      "outputs": [],
      "source": [
        "# TODO: Expliquer une prédiction individuelle\n",
        "# Choisir une fraude correctement détectée et analyser pourquoi\n",
        "# SHAP force plot montre la contribution de chaque feature à la prédiction\n",
        "\n",
        "fraud_idx = y_test[y_test == 1].index[0]\n",
        "fraud_sample_idx = X_test.index.get_loc(fraud_idx)\n",
        "\n",
        "if fraud_sample_idx < 100: # Si dans notre échantillon\n",
        "    print(f\"Analyse de la transaction {fraud_idx} (Fraude)\")\n",
        "    print(f\"Probabilité prédite: {best_model.predict_proba(X_test.iloc[[fraud_sample_idx]])[:,1][0]:.4f}\")\n",
        "\n",
        "    shap.force_plot(\n",
        "    explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
        "    shap_values_plot[fraud_sample_idx],\n",
        "    X_test_sample.iloc[fraud_sample_idx],\n",
        "    matplotlib=True,\n",
        "    show=False\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LBbstCaABOr"
      },
      "source": [
        "### QUESTION 7\n",
        "**Interprétez les Feature Importances :**\n",
        "\n",
        "1. Les features créées (Feature Engineering) sont-elles utiles ?\n",
        "2. Y a-t-il des surprises (features inattendues importantes) ?\n",
        "3. MDI vs Permutation Importance: quelles différences observez-vous ?\n",
        "4. SHAP: quelles features contribuent le plus aux prédictions de fraude ?\n",
        "5. Pourrait-on simplifier le modèle en retirant des features peu importantes ?\n",
        "\n",
        "**Vos réponses :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80D5HWPaABOr"
      },
      "source": [
        "```\n",
        "1. ...\n",
        "\n",
        "2. ...\n",
        "\n",
        "3. ...\n",
        "\n",
        "4. ...\n",
        "\n",
        "5. ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pAcLQhhABOr"
      },
      "source": [
        "### 4.2 Courbes ROC et Precision-Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlnVEd--ABOr"
      },
      "outputs": [],
      "source": [
        "# TODO: Tracer les courbes ROC et Precision-Recall côte à côte\n",
        "# 1. Prédire les probabilités avec predict_proba()\n",
        "# 2. Calculer les courbes avec roc_curve() et precision_recall_curve()\n",
        "# 3. Visualiser avec plt.subplot(1, 2, 1) et plt.subplot(1, 2, 2)\n",
        "\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr, tpr, roc_thresholds = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_proba)\n",
        "avg_precision = average_precision_score(y_test, y_proba)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(recall, precision, color='purple', lw=2, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNfjmTGJABOr"
      },
      "source": [
        "### 4.3 Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07Aid4mjABOr"
      },
      "outputs": [],
      "source": [
        "# TODO: Tracer les Learning Curves\n",
        "# Utiliser learning_curve de sklearn\n",
        "# Paramètres: cv=5, scoring='average_precision', train_sizes=np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    best_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='average_precision',\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
        "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Cross-validation score')\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
        "plt.xlabel('Training Size')\n",
        "plt.ylabel('Average Precision')\n",
        "plt.title('Learning Curves')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXJJvm1nABOr"
      },
      "source": [
        "### 4.3bis Calibration des Probabilités"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2gPSQiqABOr"
      },
      "outputs": [],
      "source": [
        "# TODO: Vérifier la calibration du modèle\n",
        "# Un modèle bien calibré: si proba=0.8, alors 80% des prédictions sont correctes\n",
        "# Méthode: Tracer la courbe de calibration (reliability diagram)\n",
        "# Axe X: Probabilité prédite (bins)\n",
        "# Axe Y: Fraction réelle de positifs dans chaque bin\n",
        "# Ligne diagonale = calibration parfaite\n",
        "\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# Calculer la courbe de calibration\n",
        "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        " y_test,\n",
        " y_proba_optimized,\n",
        " n_bins=10,\n",
        " strategy='uniform'\n",
        ")\n",
        "\n",
        "# Visualiser\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(mean_predicted_value, fraction_of_positives, 's-', label='Modèle')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Calibration parfaite')\n",
        "plt.xlabel('Probabilité prédite moyenne')\n",
        "plt.ylabel('Fraction de positifs')\n",
        "plt.title('Courbe de Calibration')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interprétation:\")\n",
        "print(\"- Si proche de la diagonale: modèle bien calibré\")\n",
        "print(\"- Si au-dessus: modèle sous-estime les probabilités\")\n",
        "print(\"- Si en-dessous: modèle surestime les probabilités\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m3-bJW8ABOr"
      },
      "outputs": [],
      "source": [
        "# TODO: Appliquer la calibration si nécessaire\n",
        "# Méthode: CalibratedClassifierCV avec Platt Scaling ou Isotonic Regression\n",
        "# Platt Scaling: Ajuste une régression logistique sur les probabilités\n",
        "# Formule: P_calibrated = 1 / (1 + exp(A × log(p/(1-p)) + B))\n",
        "# Isotonic Regression: Ajuste une fonction monotone non-paramétrique\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Calibrer le modèle\n",
        "calibrated_model = CalibratedClassifierCV(\n",
        " best_model,\n",
        " method='sigmoid', # Platt Scaling\n",
        " cv=5\n",
        ")\n",
        "\n",
        "# Entraîner sur le train\n",
        "calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédire sur le test\n",
        "y_proba_calibrated = calibrated_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Comparer les performances\n",
        "print(\"\\nComparaison avant/après calibration:\")\n",
        "print(f\"PR-AUC avant: {average_precision_score(y_test, y_proba_optimized):.4f}\")\n",
        "print(f\"PR-AUC après: {average_precision_score(y_test, y_proba_calibrated):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwUkEXN8ABOr"
      },
      "source": [
        "### QUESTION 8\n",
        "**Diagnostiquez le modèle :**\n",
        "\n",
        "1. Le modèle est-il en overfitting, underfitting ou bon fit ?\n",
        "2. Le modèle bénéficierait-il de plus de données ?\n",
        "3. Quelles actions recommanderiez-vous pour améliorer le modèle ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjFo_cNBABOr"
      },
      "source": [
        "### 4.4 Optimisation du Seuil de Décision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwHWDPF7ABOr"
      },
      "outputs": [],
      "source": [
        "# TODO: Trouver le seuil optimal maximisant le F1-Score\n",
        "# 1. Calculer precision/recall pour tous les seuils avec precision_recall_curve()\n",
        "# 2. Calculer F1 pour chaque seuil: F1 = 2 * (P * R) / (P + R)\n",
        "# 3. Trouver le seuil qui maximise F1\n",
        "# 4. Comparer les métriques avec seuil 0.5 vs seuil optimal\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "y_pred_default = (y_proba >= 0.5).astype(int)\n",
        "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "metrics_default = {\n",
        "    \"Precision\": precision_score(y_test, y_pred_default),\n",
        "    \"Recall\": recall_score(y_test, y_pred_default),\n",
        "    \"F1\": f1_score(y_test, y_pred_default)\n",
        "}\n",
        "\n",
        "metrics_optimal = {\n",
        "    \"Precision\": precision_score(y_test, y_pred_optimal),\n",
        "    \"Recall\": recall_score(y_test, y_pred_optimal),\n",
        "    \"F1\": f1_score(y_test, y_pred_optimal)\n",
        "}\n",
        "\n",
        "print(f\"Seuil optimal: {optimal_threshold:.3f}\")\n",
        "print(\"Metrics seuil 0.5:\", metrics_default)\n",
        "print(\"Metrics seuil optimal:\", metrics_optimal)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGsqMfPuABOr"
      },
      "source": [
        "### QUESTION 9\n",
        "**Analysez l'optimisation du seuil :**\n",
        "\n",
        "1. Quel est l'impact sur Precision et Recall ?\n",
        "2. Quel seuil recommanderiez-vous en production ? Pourquoi ?\n",
        "3. Comment choisir entre privilégier Precision ou Recall selon le contexte métier ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAmnD0QbABOr"
      },
      "source": [
        "---\n",
        "## PARTIE 5 : DÉPLOIEMENT & PRODUCTION (1h)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dThYotYABOr"
      },
      "source": [
        "### 5.1 Validation Temporelle (TimeSeriesSplit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBnof93zABOr"
      },
      "outputs": [],
      "source": [
        "# TODO: Valider le modèle avec TimeSeriesSplit\n",
        "# Comparer avec StratifiedKFold\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, StratifiedKFold\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "scores_ts = cross_val_score(best_model, X_train, y_train, cv=tscv, scoring='average_precision', n_jobs=-1)\n",
        "scores_skf = cross_val_score(best_model, X_train, y_train, cv=skf, scoring='average_precision', n_jobs=-1)\n",
        "\n",
        "print(\"TimeSeriesSplit Average Precision:\", scores_ts, \"Mean:\", scores_ts.mean())\n",
        "print(\"StratifiedKFold Average Precision:\", scores_skf, \"Mean:\", scores_skf.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbHOsOwOABOr"
      },
      "source": [
        "### 5.2 Sérialisation du Modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIelNSTyABOs"
      },
      "outputs": [],
      "source": [
        "# TODO: Sauvegarder le meilleur modèle (pipeline complet)\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "model_path = '../models/best_model.pkl'\n",
        "joblib.dump(best_model, model_path)\n",
        "print(f\"Modèle sauvegardé dans : {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUeBAi59ABOs"
      },
      "outputs": [],
      "source": [
        "# TODO: Sauvegarder les métadonnées\n",
        "# Inclure: version, date, paramètres, scores, seuil optimal, features, etc.\n",
        "\n",
        "metadata.update({\n",
        "    'model_params': best_model.get_params(),\n",
        "    'average_precision_train': cross_val_score(best_model, X_train, y_train, cv=5, scoring='average_precision').mean(),\n",
        "    'average_precision_test': average_precision_score(y_test, y_proba),\n",
        "    'optimal_threshold': optimal_threshold,\n",
        "    'feature_names': list(X_train.columns)\n",
        "})\n",
        "\n",
        "metadata_path = '../models/best_model_metadata.pkl'\n",
        "joblib.dump(metadata, metadata_path)\n",
        "print(f\"Métadonnées sauvegardées dans : {metadata_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtoC6LuIABOs"
      },
      "source": [
        "### 5.3 Test de Chargement et Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9jZL9XkABOs"
      },
      "outputs": [],
      "source": [
        "# TODO: Charger le modèle sauvegardé et tester une prédiction\n",
        "# 1. Charger avec joblib.load()\n",
        "# 2. Prédire sur un échantillon du test\n",
        "# 3. Afficher les résultats\n",
        "\n",
        "loaded_model = joblib.load('../models/best_model.pkl')\n",
        "\n",
        "X_sample = X_test.iloc[:5]\n",
        "y_sample_true = y_test.iloc[:5]\n",
        "\n",
        "y_sample_proba = loaded_model.predict_proba(X_sample)[:, 1]\n",
        "y_sample_pred = (y_sample_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "for i in range(len(X_sample)):\n",
        "    print(f\"Échantillon {i+1}: Probabilité={y_sample_proba[i]:.3f}, Prédiction={y_sample_pred[i]}, Vérité={y_sample_true.iloc[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEhUSm9HABOs"
      },
      "source": [
        "### 5.4 Création d'une API de Prédiction (Flask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNP6v5vcABOs"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer un script Flask pour l'API\n",
        "# Structure:\n",
        "# - Endpoint POST /predict\n",
        "# - Input: JSON avec les features d'une transaction\n",
        "# - Output: JSON avec {\"is_fraud\": bool, \"probability\": float, \"risk_level\": str}\n",
        "\n",
        "# Créer le fichier api_fraud_detection.py\n",
        "api_code = '''\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Charger le modèle au démarrage\n",
        "model = joblib.load('models/fraud_detector_v1.joblib')\n",
        "metadata = joblib.load('models/metadata_v1.joblib')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        " \"\"\"\n",
        " Endpoint de prédiction\n",
        " Input JSON: {\"Time\": float, \"V1\": float, ..., \"Amount\": float}\n",
        " Output JSON: {\"is_fraud\": bool, \"probability\": float, \"risk_level\": str}\n",
        " \"\"\"\n",
        " try:\n",
        " # Récupérer les données\n",
        " data = request.get_json()\n",
        "\n",
        " # Convertir en DataFrame\n",
        " df = pd.DataFrame([data])\n",
        "\n",
        " # Prédire\n",
        " proba = model.predict_proba(df)[:, 1][0]\n",
        " threshold = metadata.get('optimal_threshold', 0.5)\n",
        " is_fraud = proba >= threshold\n",
        "\n",
        " # Déterminer le niveau de risque\n",
        " if proba < 0.3:\n",
        " risk_level = 'low'\n",
        " elif proba < 0.6:\n",
        " risk_level = 'medium'\n",
        " elif proba < 0.85:\n",
        " risk_level = 'high'\n",
        " else:\n",
        " risk_level = 'critical'\n",
        "\n",
        " # Retourner la réponse\n",
        " return jsonify({\n",
        " 'is_fraud': bool(is_fraud),\n",
        " 'probability': float(proba),\n",
        " 'risk_level': risk_level,\n",
        " 'threshold_used': float(threshold)\n",
        " })\n",
        "\n",
        " except Exception as e:\n",
        " return jsonify({'error': str(e)}), 400\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        " \"\"\"Endpoint de santé\"\"\"\n",
        " return jsonify({'status': 'ok', 'model_version': metadata.get('model_version', 'unknown')})\n",
        "\n",
        "if __name__ == '__main__':\n",
        " app.run(host='0.0.0.0', port=5000, debug=False)\n",
        "'''\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "with open('../api_fraud_detection.py', 'w') as f:\n",
        " f.write(api_code)\n",
        "\n",
        "print(\"API Flask créée: ../api_fraud_detection.py\")\n",
        "print(\"\\nPour lancer l'API:\")\n",
        "print(\" python api_fraud_detection.py\")\n",
        "print(\"\\nPour tester:\")\n",
        "print(\" curl -X POST http://localhost:5000/predict -H 'Content-Type: application/json' -d '{...}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmJFs7nNABOs"
      },
      "source": [
        "### 5.5 Tests Unitaires du Modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDTGCIhiABOs"
      },
      "outputs": [],
      "source": [
        "# TODO: Créer des tests unitaires pour valider le modèle\n",
        "# Tests à implémenter:\n",
        "# 1. Test de chargement du modèle\n",
        "# 2. Test de prédiction sur des données valides\n",
        "# 3. Test de robustesse (valeurs manquantes, outliers)\n",
        "# 4. Test de performance (temps de prédiction < 100ms)\n",
        "\n",
        "import unittest\n",
        "import time\n",
        "\n",
        "class TestFraudDetector(unittest.TestCase):\n",
        "\n",
        " @classmethod\n",
        " def setUpClass(cls):\n",
        " \"\"\"Charger le modèle une fois pour tous les tests\"\"\"\n",
        " cls.model = joblib.load('../models/fraud_detector_v1.joblib')\n",
        " cls.sample_data = X_test.iloc[:10]\n",
        "\n",
        " def test_model_loading(self):\n",
        " \"\"\"Test: Le modèle se charge correctement\"\"\"\n",
        " self.assertIsNotNone(self.model)\n",
        " print(\"Test chargement: OK\")\n",
        "\n",
        " def test_prediction_shape(self):\n",
        " \"\"\"Test: Les prédictions ont la bonne forme\"\"\"\n",
        " predictions = self.model.predict(self.sample_data)\n",
        " self.assertEqual(len(predictions), len(self.sample_data))\n",
        " print(\"Test shape prédictions: OK\")\n",
        "\n",
        " def test_prediction_values(self):\n",
        " \"\"\"Test: Les prédictions sont dans [0, 1]\"\"\"\n",
        " probas = self.model.predict_proba(self.sample_data)[:, 1]\n",
        " self.assertTrue(all(0 <= p <= 1 for p in probas))\n",
        " print(\"Test valeurs prédictions: OK\")\n",
        "\n",
        " def test_prediction_time(self):\n",
        " \"\"\"Test: Temps de prédiction < 100ms pour 10 transactions\"\"\"\n",
        " start = time.time()\n",
        " _ = self.model.predict(self.sample_data)\n",
        " elapsed = (time.time() - start) * 1000 # en ms\n",
        " self.assertLess(elapsed, 100)\n",
        " print(f\"Test temps prédiction: {elapsed:.2f}ms < 100ms OK\")\n",
        "\n",
        "# Exécuter les tests\n",
        "if __name__ == '__main__':\n",
        " suite = unittest.TestLoader().loadTestsFromTestCase(TestFraudDetector)\n",
        " runner = unittest.TextTestRunner(verbosity=2)\n",
        " result = runner.run(suite)\n",
        "\n",
        " print(f\"\\nTests exécutés: {result.testsRun}\")\n",
        " print(f\"Succès: {result.testsRun - len(result.failures) - len(result.errors)}\")\n",
        " print(f\"Échecs: {len(result.failures)}\")\n",
        " print(f\"Erreurs: {len(result.errors)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FtuwrKBABOs"
      },
      "source": [
        "---\n",
        "## SYNTHÈSE FINALE\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PZIVvjmABOs"
      },
      "source": [
        "### QUESTION 10 - BILAN GLOBAL\n",
        "**Rédigez une synthèse de votre travail (10-15 lignes) :**\n",
        "\n",
        "1. **Performance finale** : Avez-vous atteint les objectifs (Recall ≥ 0.85, Precision maximale) ?\n",
        "2. **Feature Engineering** : Quelles features créées ont été les plus utiles ?\n",
        "3. **Optimisation** : Quel a été l'impact de GridSearch et de l'ajustement du seuil ?\n",
        "4. **Déploiement** : Le modèle est-il prêt pour la production ? Quelles précautions ?\n",
        "5. **Améliorations futures** : Que pourriez-vous faire pour améliorer encore le modèle ?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
